{"cells":[{"attachments":{},"cell_type":"markdown","id":"b52452b1-90e7-4e77-a4aa-4109c5fb79c4","metadata":{"language":"python"},"source":"<img src = \"https://github.com/singlestore-labs/spaces-notebooks/blob/e551e274bb67bb1e5081131ee1150cdba713fc43/common/images/singlestore-jupyter.png?raw=true\">"},{"attachments":{},"cell_type":"markdown","id":"e83a3630-3c94-4bc6-ab80-18563b926388","metadata":{"language":"python"},"source":"<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/browser.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Apache Spark + OpenAI for Personalized Banking Services, Part 3</h1>\n    </div>\n</div>"},{"cell_type":"code","execution_count":4,"id":"31d548b8-4622-422a-9bbd-468477ee88fb","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:53:55.997919Z","iopub.status.busy":"2024-04-16T15:53:55.997653Z","iopub.status.idle":"2024-04-16T15:53:56.441762Z","shell.execute_reply":"2024-04-16T15:53:56.441128Z","shell.execute_reply.started":"2024-04-16T15:53:55.997898Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip cache purge --quiet"},{"cell_type":"code","execution_count":5,"id":"4aed2148-2b94-4eb0-95e1-dd6e9a2b3dc9","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:53:56.443999Z","iopub.status.busy":"2024-04-16T15:53:56.442934Z","iopub.status.idle":"2024-04-16T15:54:35.202039Z","shell.execute_reply":"2024-04-16T15:54:35.201374Z","shell.execute_reply.started":"2024-04-16T15:53:56.443980Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting package metadata (current_repodata.json): ...working... done\nSolving environment: ...working... done\n\n# All requested packages already installed.\n\n"}],"source":"!conda install -y --quiet -c conda-forge openjdk pyspark"},{"cell_type":"code","execution_count":6,"id":"7f8b6247-0e7e-4a95-832b-c116cc8192f9","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:54:35.203322Z","iopub.status.busy":"2024-04-16T15:54:35.203036Z","iopub.status.idle":"2024-04-16T15:54:40.620410Z","shell.execute_reply":"2024-04-16T15:54:40.619702Z","shell.execute_reply.started":"2024-04-16T15:54:35.203287Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip uninstall langchain-openai -y --quiet\n!pip install openai==0.28 --quiet\n!pip install nltk --quiet"},{"cell_type":"code","execution_count":7,"id":"c3923018-1424-4586-ad14-242ad6eafa78","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:54:40.622642Z","iopub.status.busy":"2024-04-16T15:54:40.622411Z","iopub.status.idle":"2024-04-16T15:54:51.405623Z","shell.execute_reply":"2024-04-16T15:54:51.405116Z","shell.execute_reply.started":"2024-04-16T15:54:40.622619Z"},"language":"python","trusted":true},"outputs":[{"name":"stdin","output_type":"stream","text":"OpenAI API Key: ········\n"}],"source":"import getpass\nimport openai\n\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"},{"cell_type":"code","execution_count":8,"id":"a3a23d21-013d-412e-a120-4c56d9111af8","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:54:51.407043Z","iopub.status.busy":"2024-04-16T15:54:51.406284Z","iopub.status.idle":"2024-04-16T15:54:51.410356Z","shell.execute_reply":"2024-04-16T15:54:51.409879Z","shell.execute_reply.started":"2024-04-16T15:54:51.407020Z"},"language":"python","trusted":true},"outputs":[],"source":"import os\n\nos.makedirs(\"jars\", exist_ok = True)\nos.makedirs(\"data\", exist_ok = True)"},{"cell_type":"code","execution_count":9,"id":"d935b474-40a7-46ec-9ded-51cc2a572ca3","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:54:51.411502Z","iopub.status.busy":"2024-04-16T15:54:51.411102Z","iopub.status.idle":"2024-04-16T15:54:51.692509Z","shell.execute_reply":"2024-04-16T15:54:51.691952Z","shell.execute_reply.started":"2024-04-16T15:54:51.411482Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"JAR files downloaded successfully\n"}],"source":"import requests\n\ndef download_jar(url, destination):\n    response = requests.get(url)\n    with open(destination, \"wb\") as f:\n        f.write(response.content)\n\njar_urls = [\n    (\"https://repo1.maven.org/maven2/com/singlestore/singlestore-jdbc-client/1.2.1/singlestore-jdbc-client-1.2.1.jar\", \"jars/singlestore-jdbc-client-1.2.1.jar\"),\n    (\"https://repo1.maven.org/maven2/com/singlestore/singlestore-spark-connector_2.12/4.1.5-spark-3.5.0/singlestore-spark-connector_2.12-4.1.5-spark-3.5.0.jar\", \"jars/singlestore-spark-connector_2.12-4.1.5-spark-3.5.0.jar\"),\n    (\"https://repo1.maven.org/maven2/org/apache/commons/commons-dbcp2/2.12.0/commons-dbcp2-2.12.0.jar\", \"jars/commons-dbcp2-2.12.0.jar\"),\n    (\"https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.12.0/commons-pool2-2.12.0.jar\", \"jars/commons-pool2-2.12.0.jar\"),\n    (\"https://repo1.maven.org/maven2/io/spray/spray-json_3/1.3.6/spray-json_3-1.3.6.jar\", \"jars/spray-json_3-1.3.6.jar\")\n]\n\nfor url, destination in jar_urls:\n    download_jar(url, destination)\n\nprint(\"JAR files downloaded successfully\")"},{"cell_type":"code","execution_count":10,"id":"de40d2d2-3558-4d47-bf86-a6d766b8d5d8","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:54:51.694548Z","iopub.status.busy":"2024-04-16T15:54:51.694340Z","iopub.status.idle":"2024-04-16T15:54:56.238967Z","shell.execute_reply":"2024-04-16T15:54:56.238280Z","shell.execute_reply.started":"2024-04-16T15:54:51.694534Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"24/04/16 15:54:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/04/16 15:54:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"}],"source":"from pyspark.sql import SparkSession\n\n# Create a Spark session\nspark = (SparkSession\n             .builder\n             .config(\"spark.jars\", \",\".join([destination for _, destination in jar_urls]))\n             .appName(\"Spark Webinar\")\n             .getOrCreate()\n        )\n\nspark.sparkContext.setLogLevel(\"ERROR\")"},{"cell_type":"code","execution_count":11,"id":"06a810e8-bc76-4f9e-95b9-51db46304828","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:54:56.239823Z","iopub.status.busy":"2024-04-16T15:54:56.239666Z","iopub.status.idle":"2024-04-16T15:54:56.860164Z","shell.execute_reply":"2024-04-16T15:54:56.859667Z","shell.execute_reply.started":"2024-04-16T15:54:56.239806Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw to /home/jovyan/nltk_data...\n[nltk_data]   Package omw is already up-to-date!\n"},{"data":{"text/plain":"True"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":"import nltk\nimport random\nfrom nltk.corpus import wordnet as wn\nfrom nltk.tokenize import word_tokenize\n\n# Download NLTK\nnltk.download(\"punkt\")\nnltk.download(\"averaged_perceptron_tagger\")\nnltk.download(\"wordnet\")\nnltk.download(\"omw\")"},{"cell_type":"code","execution_count":12,"id":"cafc9dbb-0b3f-4054-a208-7d5a1d60e54f","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:54:56.861335Z","iopub.status.busy":"2024-04-16T15:54:56.860968Z","iopub.status.idle":"2024-04-16T15:55:04.503301Z","shell.execute_reply":"2024-04-16T15:55:04.502692Z","shell.execute_reply.started":"2024-04-16T15:54:56.861315Z"},"language":"python","trusted":true},"outputs":[],"source":"# Define the directory to save the files\noutput_dir = \"data\"\n\n# Generate meaningful sentences\ndef generate_meaningful_sentence():\n    # Choose a random set of synonyms from WordNet\n    synset = random.choice(list(wn.all_synsets()))\n\n    # Generate a sentence\n    definition = synset.definition()\n    tokens = word_tokenize(definition)\n\n    # Capitalise the first word and end with a period\n    tokens[0] = tokens[0].capitalize()\n    tokens[-1] = tokens[-1] + \".\"\n\n    return \" \".join(tokens)\n\n# Number of files to generate\nnum_files = 5\n\n# Number of sentences in each file\nnum_sentences_per_file = 1\n\n# Generate text files\nfor i in range(num_files):\n    file_path = os.path.join(output_dir, f\"file_{i+1}.txt\")\n    with open(file_path, \"w\") as file:\n        for _ in range(num_sentences_per_file):\n            # Generate a meaningful sentence\n            sentence = generate_meaningful_sentence()\n            file.write(sentence + \"\\n\")"},{"cell_type":"code","execution_count":13,"id":"db8ec8cb-d0e1-4bd9-bec6-fe63c9f09ba3","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:55:04.505911Z","iopub.status.busy":"2024-04-16T15:55:04.505402Z","iopub.status.idle":"2024-04-16T15:55:04.529341Z","shell.execute_reply":"2024-04-16T15:55:04.528819Z","shell.execute_reply.started":"2024-04-16T15:55:04.505891Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"File: data/file_1.txt\nJump on skis.\n----------------------\nFile: data/file_2.txt\nHybrid willow usually not strongly weeping in habit.\n----------------------\nFile: data/file_3.txt\nWide-ranging light-brown frog of moist North American woodlands especially spruce.\n----------------------\nFile: data/file_4.txt\nA tear gas that is stronger than CN gas but wears off faster ; can be deployed by grenades or cluster bombs ; can cause skin burns and fatal pulmonary edema.\n----------------------\nFile: data/file_5.txt\nIndicating continuing action ; continuously or steadily.\n----------------------\n"}],"source":"%%bash\n\nfor file in data/*.txt; do\n    echo \"File: $file\"\n    cat \"$file\"\n    echo \"----------------------\"\ndone"},{"cell_type":"code","execution_count":14,"id":"159866a7-ddbb-4f71-9486-19e40d407c58","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:55:04.529944Z","iopub.status.busy":"2024-04-16T15:55:04.529810Z","iopub.status.idle":"2024-04-16T15:55:40.694406Z","shell.execute_reply":"2024-04-16T15:55:40.693868Z","shell.execute_reply.started":"2024-04-16T15:55:04.529933Z"},"language":"python","trusted":true},"outputs":[{"name":"stdin","output_type":"stream","text":"Password: ········\n"}],"source":"import getpass\n\nhost = \"svc-201fd973-4b68-402d-aa09-0bf89add18eb-dml.aws-oregon-4.svc.singlestore.com\"\nport = \"3306\"\ncluster = host + \":\" + port\n\npassword = getpass.getpass(\"Password:\")"},{"cell_type":"code","execution_count":15,"id":"25ab713c-e57a-428b-acff-8167d6a1f575","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:55:40.695617Z","iopub.status.busy":"2024-04-16T15:55:40.695237Z","iopub.status.idle":"2024-04-16T15:55:41.619617Z","shell.execute_reply":"2024-04-16T15:55:41.619041Z","shell.execute_reply.started":"2024-04-16T15:55:40.695597Z"},"language":"python","trusted":true},"outputs":[],"source":"spark.conf.set(\"spark.datasource.singlestore.ddlEndpoint\", cluster)\nspark.conf.set(\"spark.datasource.singlestore.user\", \"admin\")\nspark.conf.set(\"spark.datasource.singlestore.password\", password)\nspark.conf.set(\"spark.datasource.singlestore.disablePushdown\", \"false\")"},{"cell_type":"code","execution_count":19,"id":"65b6fc2b-427e-455f-af29-92180c12940e","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:56:15.143672Z","iopub.status.busy":"2024-04-16T15:56:15.143467Z","iopub.status.idle":"2024-04-16T15:56:15.610331Z","shell.execute_reply":"2024-04-16T15:56:15.609745Z","shell.execute_reply.started":"2024-04-16T15:56:15.143658Z"},"language":"sql","trusted":true},"outputs":[{"data":{"text/html":"<table>\n    <thead>\n        <tr>\n        </tr>\n    </thead>\n    <tbody>\n    </tbody>\n</table>","text/plain":"++\n||\n++\n++"},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":"%%sql\nUSE spark_demo;\n\nDROP TABLE IF EXISTS comments;\nCREATE TABLE IF NOT EXISTS comments (\n     value TEXT,\n     file_name TEXT,\n     embedding VECTOR(1536) NOT NULL\n);"},{"cell_type":"code","execution_count":20,"id":"4aa6262d-7007-44f8-a932-c5deb8d0cfc0","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:56:25.915870Z","iopub.status.busy":"2024-04-16T15:56:25.915575Z","iopub.status.idle":"2024-04-16T15:56:25.920937Z","shell.execute_reply":"2024-04-16T15:56:25.920400Z","shell.execute_reply.started":"2024-04-16T15:56:25.915854Z"},"language":"python","trusted":true},"outputs":[],"source":"from pyspark.sql.functions import input_file_name, udf\nfrom pyspark.sql.types import StringType\n\nopenai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\n# Generate embeddings for text\ndef generate_embeddings(text):\n    # Generate embeddings for text using OpenAI\n    return openai.Embedding.create(\n        input = text,\n        engine = \"text-embedding-3-small\"\n    ).data[0].embedding\n\n# Register the function as a UDF\ngenerate_embeddings_udf = udf(generate_embeddings, StringType())"},{"cell_type":"code","execution_count":21,"id":"b9b0bdff-b9a1-4992-9470-fbf4a6d7d9f0","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:56:33.759811Z","iopub.status.busy":"2024-04-16T15:56:33.759523Z","iopub.status.idle":"2024-04-16T15:56:45.576247Z","shell.execute_reply":"2024-04-16T15:56:45.575687Z","shell.execute_reply.started":"2024-04-16T15:56:33.759794Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"                                                                                \r"}],"source":"import time\n\ninput_dir = output_dir\n\n# Read from the directory\ndf = (spark.readStream\n    .format(\"text\")\n    .option(\"path\", input_dir)\n    .load()\n    .withColumn(\"file_name\", input_file_name())\n)\n\n# Apply the function to the DataFrame to generate embeddings for each row\ndf_with_embeddings = df.withColumn(\"embedding\", generate_embeddings_udf(\"value\"))\n\n# Write each batch of data to SingleStore\ndef write_to_singlestore(df_with_embeddings, epoch_id):\n    (df_with_embeddings.write\n         .format(\"singlestore\")\n         .option(\"loadDataCompression\", \"LZ4\")\n         .mode(\"append\")\n         .save(\"spark_demo.comments\")\n    )\n\n# Write the streaming DataFrame to SingleStore using foreachBatch\nquery = (df_with_embeddings.writeStream\n    .foreachBatch(write_to_singlestore)\n    .start()\n)\n\n# Wait for the query to finish processing\nwhile query.isActive:\n    time.sleep(1)\n    if not query.status[\"isDataAvailable\"]:\n        query.stop()"},{"cell_type":"code","execution_count":22,"id":"a0c6b8a6-4164-44ff-9fd4-c12f14ef9219","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:56:56.086316Z","iopub.status.busy":"2024-04-16T15:56:56.086016Z","iopub.status.idle":"2024-04-16T15:56:56.399590Z","shell.execute_reply":"2024-04-16T15:56:56.398995Z","shell.execute_reply.started":"2024-04-16T15:56:56.086298Z"},"language":"sql","trusted":true},"outputs":[{"data":{"text/html":"<table>\n    <thead>\n        <tr>\n            <th>value</th>\n            <th>file_name</th>\n            <th>embedding</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>Indicating continuing action ;</td>\n            <td>file_5.txt</td>\n            <td>[0.0237321071,0.0341514125,0.0182303879,0.03942219</td>\n        </tr>\n        <tr>\n            <td>Wide-ranging light-brown frog </td>\n            <td>file_3.txt</td>\n            <td>[-0.00194031477,-0.0134520773,0.0547336452,0.01292</td>\n        </tr>\n        <tr>\n            <td>Jump on skis.</td>\n            <td>file_1.txt</td>\n            <td>[0.030417813,0.0341594741,0.0108481226,-0.03507469</td>\n        </tr>\n        <tr>\n            <td>A tear gas that is stronger th</td>\n            <td>file_4.txt</td>\n            <td>[0.0302113201,0.0374153629,0.00788259227,0.0550957</td>\n        </tr>\n        <tr>\n            <td>Hybrid willow usually not stro</td>\n            <td>file_2.txt</td>\n            <td>[0.0352415368,0.0366364606,-0.00554679148,0.038584</td>\n        </tr>\n    </tbody>\n</table>","text/plain":"+--------------------------------+------------+----------------------------------------------------+\n|             value              | file_name  |                     embedding                      |\n+--------------------------------+------------+----------------------------------------------------+\n| Indicating continuing action ; | file_5.txt | [0.0237321071,0.0341514125,0.0182303879,0.03942219 |\n| Wide-ranging light-brown frog  | file_3.txt | [-0.00194031477,-0.0134520773,0.0547336452,0.01292 |\n|         Jump on skis.          | file_1.txt | [0.030417813,0.0341594741,0.0108481226,-0.03507469 |\n| A tear gas that is stronger th | file_4.txt | [0.0302113201,0.0374153629,0.00788259227,0.0550957 |\n| Hybrid willow usually not stro | file_2.txt | [0.0352415368,0.0366364606,-0.00554679148,0.038584 |\n+--------------------------------+------------+----------------------------------------------------+"},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":"%%sql\nUSE spark_demo;\n\nSELECT\n    SUBSTR(value, 1, 30) AS value,\n    SUBSTR(file_name, LENGTH(file_name) - 9) AS file_name,\n    SUBSTR(embedding, 1, 50) AS embedding\nFROM comments;"},{"cell_type":"code","execution_count":23,"id":"240a9c43-6419-4a5a-b5f8-73bc7d5afbca","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:57:20.189000Z","iopub.status.busy":"2024-04-16T15:57:20.188747Z","iopub.status.idle":"2024-04-16T15:57:20.376801Z","shell.execute_reply":"2024-04-16T15:57:20.376280Z","shell.execute_reply.started":"2024-04-16T15:57:20.188984Z"},"language":"python","trusted":true},"outputs":[],"source":"# Define the text for which you want an embedding\ntext = \"frog\"\n\n# Request the embedding\nresponse = openai.Embedding.create(\n    input = text,\n    engine= \"text-embedding-3-small\"\n)\n\n# Get the embedding from the response\nquery_string = str(response.data[0].embedding)"},{"cell_type":"code","execution_count":24,"id":"67896e42-4413-4816-9b46-51e5a81dfd4a","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:57:24.204523Z","iopub.status.busy":"2024-04-16T15:57:24.204274Z","iopub.status.idle":"2024-04-16T15:57:24.208625Z","shell.execute_reply":"2024-04-16T15:57:24.208086Z","shell.execute_reply.started":"2024-04-16T15:57:24.204507Z"},"language":"python","trusted":true},"outputs":[],"source":"%config SqlMagic.named_parameters = True"},{"cell_type":"code","execution_count":25,"id":"ef4584f1-c945-4c4f-8b62-7dccaa18e49e","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:57:28.889668Z","iopub.status.busy":"2024-04-16T15:57:28.889409Z","iopub.status.idle":"2024-04-16T15:57:29.263901Z","shell.execute_reply":"2024-04-16T15:57:29.263381Z","shell.execute_reply.started":"2024-04-16T15:57:28.889652Z"},"language":"sql","trusted":true},"outputs":[{"data":{"text/html":"<table>\n    <thead>\n        <tr>\n            <th>value</th>\n            <th>file_name</th>\n            <th>similarity</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>Wide-ranging light-brown frog </td>\n            <td>file_3.txt</td>\n            <td>1.1131780208445137</td>\n        </tr>\n        <tr>\n            <td>Jump on skis.</td>\n            <td>file_1.txt</td>\n            <td>1.2943939467682306</td>\n        </tr>\n        <tr>\n            <td>Indicating continuing action ;</td>\n            <td>file_5.txt</td>\n            <td>1.3149931253318798</td>\n        </tr>\n        <tr>\n            <td>Hybrid willow usually not stro</td>\n            <td>file_2.txt</td>\n            <td>1.319062131851387</td>\n        </tr>\n        <tr>\n            <td>A tear gas that is stronger th</td>\n            <td>file_4.txt</td>\n            <td>1.3730401463567572</td>\n        </tr>\n    </tbody>\n</table>","text/plain":"+--------------------------------+------------+--------------------+\n|             value              | file_name  |     similarity     |\n+--------------------------------+------------+--------------------+\n| Wide-ranging light-brown frog  | file_3.txt | 1.1131780208445137 |\n|         Jump on skis.          | file_1.txt | 1.2943939467682306 |\n| Indicating continuing action ; | file_5.txt | 1.3149931253318798 |\n| Hybrid willow usually not stro | file_2.txt | 1.319062131851387  |\n| A tear gas that is stronger th | file_4.txt | 1.3730401463567572 |\n+--------------------------------+------------+--------------------+"},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":"%%sql\nUSE spark_demo;\n\nSELECT\n    SUBSTR(value, 1, 30) AS value,\n    SUBSTR(file_name, LENGTH(file_name) - 9) AS file_name,\n    embedding <-> :query_string AS similarity\nFROM comments\nORDER BY similarity\nLIMIT 5;"},{"cell_type":"code","execution_count":26,"id":"efad259c-6c50-4cc9-aaaa-1ebd644c75e6","metadata":{"execution":{"iopub.execute_input":"2024-04-16T15:57:35.964045Z","iopub.status.busy":"2024-04-16T15:57:35.963799Z","iopub.status.idle":"2024-04-16T15:57:36.941044Z","shell.execute_reply":"2024-04-16T15:57:36.940365Z","shell.execute_reply.started":"2024-04-16T15:57:35.964029Z"},"language":"python","trusted":true},"outputs":[],"source":"spark.stop()"}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"57e2367b-3b1b-4ffc-aa09-0bf89add18eb","defaultDatabase":"spark_demo"}},"nbformat":4,"nbformat_minor":5}